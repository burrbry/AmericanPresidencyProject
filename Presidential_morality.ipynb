{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "import csv\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# grab all speeches\n",
    "path  = \"cleaned_presidential_speeches.json\"\n",
    "with open(path) as f:\n",
    "    cleaned_speeches = json.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Presidents we want to analyze with their years served\n",
    "PRESIDENTS = {\n",
    "    'Ulysses S. Grant': [1869, 1877],\n",
    "    'Rutherford B. Hayes': [1877, 1881],\n",
    "    'James A. Garfield': [1881, 1881],\n",
    "    'Chester A. Arthur': [1881, 1885],\n",
    "    'Grover Cleveland': [1885, 1889],\n",
    "    'Benjamin Harrison': [1889, 1893],\n",
    "    'Grover Cleveland': [1893, 1897],\n",
    "    'William McKinley': [1897, 1901],\n",
    "    \"Theodore Roosevelt\": [1901,1909],\n",
    "    \"William Howard Taft\": [1909,1913],\n",
    "    \"Woodrow Wilson\": [1913,1921],\n",
    "    \"Warren G. Harding\": [1921,1923],\n",
    "    \"Calvin Coolidge\": [1923,1929],\n",
    "    \"Herbert Hoover\": [1929,1933],\n",
    "    \"Franklin D. Roosevelt\": [1933,1945],\n",
    "    \"Harry S. Truman\": [1945,1953],\n",
    "    \"Dwight D. Eisenhower\": [1953,1961],\n",
    "    \"John F. Kennedy\": [1961,1963],\n",
    "    \"Lyndon B. Johnson\": [1963,1969],\n",
    "    \"Richard Nixon\": [1969,1974],\n",
    "    \"Gerald R. Ford\": [1974,1977],\n",
    "    \"Jimmy Carter\": [1977,1981],\n",
    "    \"Ronald Reagan\": [1981,1989],\n",
    "    \"George Bush\": [1989,1993],\n",
    "    \"William J. Clinton\": [1993,2001],\n",
    "    \"George W. Bush\": [2001,2009],\n",
    "    \"Barack Obama\": [2009,2017],\n",
    "    'Donald J. Trump': [2017, 2021]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cleaning the speeches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get only speeches from presidents after Andrew Johnson served\n",
    "speeches = [speech for speech in cleaned_speeches if int(speech.get(\"date\").split(\" \")[-1]) >= 1869]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get rid of all speeches not by a president\n",
    "cleaned_presidential = []\n",
    "for i in cleaned_speeches:\n",
    "    if i['speaker'].lower() in [p.lower() for p in PRESIDENTS.keys()] and \"Presidential\" in i['categories']['primary']:\n",
    "        cleaned_presidential.append(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make sure all speeches were given during presidential years\n",
    "filtered_speeches = []\n",
    "for i in cleaned_presidential:\n",
    "    if i['speaker'].lower() in [p.lower() for p in PRESIDENTS.keys()] and \"Presidential\" in i['categories']['primary'] and i['speaker'].lower() != 'andrew johnson':\n",
    "        start_year = int(PRESIDENTS[i['speaker'].lower()][0])\n",
    "        end_year = int(PRESIDENTS[i['speaker'].lower()][1])\n",
    "        speech_year = int(i['date'][-4:])\n",
    "        if speech_year >= start_year and speech_year <= end_year:\n",
    "            filtered_speeches.append(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tokenizing and matching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#tokenize all speeches by president to be able to get proportions later on\n",
    "proportion_tokens = {}\n",
    "for president in PRESIDENTS.keys():\n",
    "    proportion_tokens[president] = Counter()\n",
    "\n",
    "for data in filtered_speeches:\n",
    "    # replace em and en dashes\n",
    "    data[\"body\"] = data[\"body\"].replace(\"\\u2013\", \" \\u2013 \")\n",
    "    data[\"body\"] = data[\"body\"].replace(\"\\u2014\", \" \\u2014 \")\n",
    "    tokens = nltk.word_tokenize(data[\"body\"])\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    token_counter = Counter(tokens)\n",
    "\n",
    "    proportion_tokens[data[\"speaker\"].lower()] += token_counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#tokenize as well as match words to the hand-curated dictionary\n",
    "path_to_json = \"ensemble_weighted/json_dicts\"\n",
    "results = {}\n",
    "\n",
    "for speech in filtered_speeches:\n",
    "    speech_year = speech['date'].split(',')[-1].strip()\n",
    "    # Grab correct dictionary for year that the speech was given\n",
    "    for file in os.listdir(path_to_json):\n",
    "        year_range = file.split(\".\")[0].split(\"-\")\n",
    "        if int(year_range[0]) <= int(speech_year) <= int(year_range[1]):\n",
    "            with open(os.path.join(path_to_json, file), 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "\n",
    "            data = speech['body']\n",
    "            data = data.replace(\"\\u2013\", \" \\u2013 \")\n",
    "            data = data.replace(\"\\u2014\", \" \\u2014 \")\n",
    "            tokens = nltk.word_tokenize(data)\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "            token_counter = Counter(tokens)\n",
    "\n",
    "            # Match the tokens to the words in the dictionary\n",
    "            for list_name, word_list in json_data.items():\n",
    "                count = 0\n",
    "                for word in word_list:\n",
    "                    if word in token_counter:\n",
    "                        count += token_counter[word]\n",
    "                if speech['speaker'] not in results:\n",
    "                    results[speech['speaker']] = {}\n",
    "                if list_name not in results[speech['speaker']]:\n",
    "                    results[speech['speaker']][list_name] = 0\n",
    "                results[speech['speaker']][list_name] += count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write results to a CSV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_name = \"unprocessed_dynamic_exact.csv\"\n",
    "with open(file_name, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # Order presidents by years they served\n",
    "    sorted_keys = sorted(results.keys(), key=lambda x: PRESIDENTS[x][0])\n",
    "    value_keys = list(results[sorted_keys[0]].keys())\n",
    "\n",
    "    header = ['Presidents'] + sorted_keys\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for value_key in value_keys:\n",
    "        row = [value_key] + [results[key][value_key] for key in sorted_keys]\n",
    "        writer.writerow(row)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Grab total tokens for each president from prior tokenization\n",
    "total_words = {}\n",
    "for president, counter in sorted(proportion_tokens.items()):\n",
    "    total_words[president] = sum(counter.values())\n",
    "\n",
    "file_name = \"unprocessed_dynamic_proportions.csv\"\n",
    "with open(file_name, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        sorted_keys = sorted(results.keys(), key=lambda x: PRESIDENTS[x][0])\n",
    "        value_keys = list(results[sorted_keys[0]].keys())\n",
    "\n",
    "        header = ['Presidents'] + sorted_keys\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # Divide matching tokens for the dictionary by the total amount of tokens by president\n",
    "        for value_key in value_keys:\n",
    "            new_row = [value_key]\n",
    "            for key in sorted_keys:\n",
    "                president_name = key.lower()\n",
    "                proportion = results[key][value_key] / total_words[president_name]\n",
    "                new_row.append(proportion)\n",
    "            writer.writerow(new_row)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
